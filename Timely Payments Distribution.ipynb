{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efde04a-fb90-4810-b489-5481953fc256",
   "metadata": {},
   "source": [
    "# <font face = 'Impact' color = '#FFAEBC' > Sample Demonstration on Machine Learning for Classification<font/>\n",
    "#### <font face = 'Times New Roman' color = '#B5E5CF'> License: GPL v3.0<font/>\n",
    "#### <font face = 'Times New Roman' color = '#B5E5CF'> Author and Trainer: Paolo Hilado MSc. (Data Science)<font/>\n",
    "This notebook provides a backgrounder in doing Machine Learning in Python employing models such as K-Nearest Neighbot, Decision Trees, Logistics Regression, Support Vector Machine, and Random Forest Classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0fa855e-cef7-4ccf-84b7-678b0e6e4205",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Business Understanding:<font/>\n",
    "\n",
    "Every business that invoices customers faces one common challenge:\n",
    "- ‚úÖ Ensuring invoices are paid on time.\n",
    "- ‚ö†Ô∏è Late payments can disrupt cash flow, increase administrative costs, and affect the company‚Äôs ability to operate efficiently.\n",
    "\n",
    "\"We Provide All\", a mid-sized B2B service provider, issues hundreds of invoices monthly to clients across various industries. Some clients pay promptly, while others consistently delay payments. The Operations Department want to anticipate payment delays so they can take preventive action such as early reminders, offering discounts, or adjusting payment terms.\n",
    "\n",
    "The QUESTION relevant to the business problem is simple but impactful:\n",
    "## ‚ÄúCan we predict whether a customer will pay their next invoice on time?‚Äù\n",
    "\n",
    "By identifying invoices at risk of late payment, the company can:\n",
    "- üéØImprove cash flow forecasting\n",
    "- üéØPrioritize follow-up actions for at-risk customers\n",
    "- üéØOffer proactive incentives or flexible payment plans\n",
    "- üéØReduce overdue receivables and collection costs\n",
    "\n",
    "This transforms a reactive collections process into a data-driven, proactive operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1519ab-82ad-4aed-a615-1e50d6c4e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0c845-7787-4e33-b98c-11e62d9f8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"timely_pay3.csv\")\n",
    "# Check out the first few records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e243c-b338-4a71-859b-61f118791b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the information about the data frame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f2b8c-92b0-466f-bb01-16ce7ef505de",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Data Understanding:<font/>\n",
    "Collaboration with the Operations Department paved way to a solid understanding of the explanatory variables and target variable relevant to the business problem. They are documented as follows:\n",
    "\n",
    "| Feature                  | Description                                                                    | Why It Matters                                                                                                |\n",
    "| ------------------------ | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------- |\n",
    "| **credit_score**         | A numeric score representing a customer‚Äôs creditworthiness (300‚Äì850).          | Higher credit scores indicate lower risk and better likelihood of on-time payments.                           |\n",
    "| **debt_to_income_ratio** | Ratio of total debt to total income, typically between 0.1‚Äì0.6 in the dataset. | Lower ratios suggest the customer has manageable debt relative to income, making timely payments more likely. |\n",
    "| **num_late_payments**    | Number of past late payments recorded (0‚Äì2 in synthetic dataset).              | Past payment behavior is a strong predictor; more late payments increase the risk of delays.                  |\n",
    "| **on_time_payment**      | Target variable: 1 if payment was on time, 0 if late.                          | The outcome we are trying to predict; understanding its drivers is key for modeling risk.                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5759ed-5a7a-4745-95d2-7338fd301109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for dataset balance or imbalance\n",
    "import qdesc as qd\n",
    "data = pd.DataFrame()\n",
    "data['col'] = df['on_time_payment'].astype('category')\n",
    "qd.freqdist(data, \"col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526fad8-1275-4959-baba-803f6f528cab",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Data Preparation:<font/>\n",
    "This presents the recipe for data explorationg and transformation in preparation for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc33f-47c6-4b2b-8e2d-e36a08fbcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# Split the dataset into train and test sets.\n",
    "# Given 11 explanatory variables we would at need > 138 observations for\n",
    "# training a regression model (Tabachnick and Fidell, 2013). The 80-20 split\n",
    "# will be used for this project. \n",
    "train, test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "print(f'''The number of records for the train set is {len(train)}.\n",
    "The number of records for the test set is {len(test)}.''')\n",
    "# Source: Tabachnick, B.G.,Fidell, L.S., 2013. Using Multivariate Statistics, \n",
    "#         6th ed. Pearson Education, Inc., Boston. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29290dac-4efe-43b3-91d4-2f3d8da16f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the explanatory variables from the outcome variable (train).\n",
    "x_train = train.drop(['on_time_payment'], axis = 1)\n",
    "y_train = train['on_time_payment']\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e4713-6764-46cc-8403-2df985a0831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the explanatory variables from the outcome variable (test).\n",
    "x_test = test.drop(['on_time_payment'], axis = 1)\n",
    "y_test = test['on_time_payment']\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2fae1-8c0a-4e00-8253-69162bad28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all the continuous variables for train set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assigning feature labels to variable continuous_vars.\n",
    "continuous_vars = ['credit_score', 'debt_to_income_ratio', 'num_late_payments',]\n",
    "\n",
    "# Initialize StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to the continuous variables and transform them.\n",
    "x_train[continuous_vars] = scaler.fit_transform(x_train[continuous_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b84f25-e303-457b-8906-da56c3d877d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all the continuous variables for test set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have your data in a DataFrame called df with continuous variables\n",
    "# Replace continuous_vars with the names of your continuous variables\n",
    "continuous_vars = ['credit_score', 'debt_to_income_ratio', 'num_late_payments',]\n",
    "\n",
    "# Fit scaler to the continuous variables and transform them\n",
    "x_test[continuous_vars] = scaler.transform(x_test[continuous_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2e698-d206-456a-8c89-1f3cdb6892e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Checking for Multicollinearity among continuous variables using correlation matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(x_train[continuous_vars].corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a1dd2-d7a5-4b6b-858c-3633ea81a54f",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Modelling: KNN<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0d008-696e-4baa-8c8e-ee48a087b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(3, 21)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# CV Score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train Score\n",
    "y_train_pred = best_knn.predict(x_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test Score\n",
    "y_pred = best_knn.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf201a-604b-4716-b973-80ad58ae45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, average='macro'),\n",
    "    \"Recall\": recall_score(y_test, y_pred, average='macro'),\n",
    "    \"F1-score\": f1_score(y_test, y_pred, average='macro')\n",
    "}\n",
    "\n",
    "results_df = np.round(pd.DataFrame(metrics, index=['Score']),2)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cad4aa-b21f-4964-af30-08aceedbab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fit the KNN Model using the hyperparameters for our best model\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Define class labels.\n",
    "class_labels = np.unique(y_test)\n",
    "\n",
    "# Create a confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
    "\n",
    "# Proper labelling of outcomes.\n",
    "tn, fp, fn, tp= confusion_matrix(y_test, y_pred, labels=class_labels).ravel()\n",
    "print(\"tp:\", tp,\"fn:\", fn,\"fp:\",fp,\"tn:\", tn )\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e31a4-6f36-4187-ad19-2e3b9afff92e",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Modelling: Decision Trees<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28014654-55d7-4cb6-9838-1cda9644fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define classifier with random state\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],       # Split criterion ('gini' or 'entropy')\n",
    "    'max_depth': [3, 5, 10, 15],         # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],          # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['log2', 'sqrt']      # Number of features to consider when looking for the best split    \n",
    "}\n",
    "\n",
    "# Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train evaluation\n",
    "y_train_pred = best_tree.predict(x_train)\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Test evaluation\n",
    "y_pred = best_tree.predict(x_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb79ab4-2847-400b-bfd6-a8f2ff186d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, average='macro'),\n",
    "    \"Recall\": recall_score(y_test, y_pred, average='macro'),\n",
    "    \"F1-score\": f1_score(y_test, y_pred, average='macro')\n",
    "}\n",
    "\n",
    "results_df = np.round(pd.DataFrame(metrics, index=['Score']),2)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d1832-7aef-449e-9782-58a03bd81dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fit the Decision Tree Model using the hyperparameters for our best model\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions using the best model on the test set.\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Define class labels.\n",
    "class_labels = np.unique(y_test)\n",
    "\n",
    "# Create a confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
    "\n",
    "# Proper labelling of outcomes.\n",
    "tn, fp, fn, tp= confusion_matrix(y_test, y_pred, labels=class_labels).ravel()\n",
    "print(\"tp:\", tp,\"fn:\", fn,\"fp:\",fp,\"tn:\", tn )\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e21a7-b58b-4706-8798-5af3da06be37",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Modelling: Logistic Regression<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877fe96-4948-42b7-8be5-aa32df979c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Proper Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=44)\n",
    "\n",
    "# Logistic Regression model with balanced classes\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42, max_iter=500)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear'],  # 'liblinear' supports both L1 and L2\n",
    "}\n",
    "\n",
    "# Grid search using accuracy\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',   \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train prediction\n",
    "y_train_pred = best_logreg.predict(x_train)\n",
    "print(\"\\nTrain Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Test prediction\n",
    "y_test_pred = best_logreg.predict(x_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d79c0-7c45-4a49-9a4b-65c877ef1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, average='macro'),\n",
    "    \"Recall\": recall_score(y_test, y_pred, average='macro'),\n",
    "    \"F1-score\": f1_score(y_test, y_pred, average='macro')\n",
    "}\n",
    "\n",
    "results_df = np.round(pd.DataFrame(metrics, index=['Score']),2)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b470a7-3152-4996-a537-0b3ea1006981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fit the Logistic Regression Model using the hyperparameters for our best model\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Print the Logistic Regression Model performance on our test set.\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Define class labels.\n",
    "class_labels = np.unique(y_test)\n",
    "\n",
    "# Compute confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
    "\n",
    "# Proper labelling of outcomes.\n",
    "tp, fn, fp, tn= confusion_matrix(y_test, y_pred, labels=class_labels).ravel()\n",
    "print(\"tp:\", tp,\"fn:\", fn,\"fp:\",fp,\"tn:\", tn )\n",
    "\n",
    "# Create a heatmap of the confusion matrix.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197ee51-c11e-4195-9bfc-90c1e33391a0",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Modelling: Random Forest<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1933e-1d85-4821-bec5-7baef259b394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Random Forest Classifier Model.\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# Define the parameters of the Random Forest Classifier for Hyperparameter Tuning.\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100,200],\n",
    "    'max_depth': [None, 5, 10,20],\n",
    "    'min_samples_split': [2, 5, 10,15]\n",
    "}\n",
    "\n",
    "# Setup the grid search with accuracy scoring\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Using GridSearchCV to determine the best model.\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and its Accuracy score\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best CV Accuracy:\", best_cv_accuracy)\n",
    "\n",
    "# Train the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_rf.predict(x_train)\n",
    "y_test_pred = best_rf.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nTrain Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29be32-69bd-4518-93dd-26bb598832a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, average='macro'),\n",
    "    \"Recall\": recall_score(y_test, y_pred, average='macro'),\n",
    "    \"F1-score\": f1_score(y_test, y_pred, average='macro')\n",
    "}\n",
    "\n",
    "results_df = np.round(pd.DataFrame(metrics, index=['Score']),2)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448820c2-49dd-48a8-8a74-9394abed5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Print the RF Model performance on our test set.\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Calculate model performance such as F1, Recall, and Precision. \n",
    "from sklearn import metrics\n",
    "print(\"Test f1 Score =\",metrics.f1_score(y_test, y_pred, pos_label = 1))\n",
    "print(\"Test recall Score =\",metrics.recall_score(y_test, y_pred, pos_label = 1))\n",
    "print(\"Test precision Score =\",metrics.precision_score(y_test, y_pred, pos_label = 1))\n",
    "\n",
    "\n",
    "# Define class labels.\n",
    "class_labels = np.unique(y_test)\n",
    "\n",
    "# Compute confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
    "\n",
    "# Proper labelling of outcomes.\n",
    "tp, fn, fp, tn= confusion_matrix(y_test, y_pred, labels=class_labels).ravel()\n",
    "print(\"tp:\", tp,\"fn:\", fn,\"fp:\",fp,\"tn:\", tn )\n",
    "\n",
    "# Create a heatmap of the confusion matrix.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cfb39e-69a1-451b-9afb-8946e1dde3d3",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#5885AF'> Saving the Model for Future Deployment<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7953741-f8f6-4fb8-87e5-9aeedabf8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the Random Forest Model.\n",
    "import pickle\n",
    "pickle.dump(best_rf, open('RFPaymodel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a6f73-58ae-49d4-a59f-4459ae697ae0",
   "metadata": {},
   "source": [
    "# Decision\n",
    "\n",
    "Given the results of the CV RMSE across the different models, Random Forest Classifier have promising model performance compared to other trained models. Its CV accuracy is consistent with Train accuracy indicating no overfit. It also performs well on the unseen test data having an accuracy of near 0.9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
